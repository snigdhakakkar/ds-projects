{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "477db378",
   "metadata": {},
   "source": [
    "##### Problem: We have a Kaggle dataset that contains tweets about a long discussion within a group of users. Here our task is to identify how many tweets are negative and positive so that we can give a conclusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5f7f1",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffe320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "import nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ad6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "\n",
    "data = pd.read_csv(\"datasets/twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9710af29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8c07c",
   "metadata": {},
   "source": [
    "The tweet column in the above dataset contains the tweets that we need to use to analyze the feelings of those engaged in the discussion. But to go further, we have to clean up a lot of errors and other special symbols because these tweets contain a lot of language errors. So here is how we can clean up the tweet column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ab37bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snigdhakakkar/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84972966",
   "metadata": {},
   "source": [
    "Stop words are a set of commonly used words in a language. Examples of stop words in English are ‚Äúa‚Äù, ‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúare‚Äù and etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so commonly used that they carry very little useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0971bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374642d9",
   "metadata": {},
   "source": [
    "In simple words stemming is reducing a word to its base word or stem in such a way that the words of similar kind lie under a common stem. For example ‚Äì The words care, cared and caring lie under the same stem ‚Äòcare‚Äô. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e000d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4fa1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd890531",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50307441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0   rt mayasolov woman shouldnt complain clean ho...  \n",
      "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...  \n",
      "2   rt urkindofbrand dawg rt  ever fuck bitch sta...  \n",
      "3             rt cganderson vivabas look like tranni  \n",
      "4   rt shenikarobert shit hear might true might f...  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4119af",
   "metadata": {},
   "source": [
    "###### Now, we would calculate the sentiment scores of these tweets and assign a label to the tweets as positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "499f8e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/snigdhakakkar/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d55f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"tweet\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"tweet\"]]\n",
    "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"tweet\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065331f",
   "metadata": {},
   "source": [
    "Now, let us select the columns from this data that we need for the rest of the task of Twitter sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5232e57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  Positive  Negative  \\\n",
      "0   rt mayasolov woman shouldnt complain clean ho...     0.147     0.157   \n",
      "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...     0.000     0.280   \n",
      "2   rt urkindofbrand dawg rt  ever fuck bitch sta...     0.000     0.577   \n",
      "3             rt cganderson vivabas look like tranni     0.333     0.000   \n",
      "4   rt shenikarobert shit hear might true might f...     0.154     0.407   \n",
      "\n",
      "   Neutral  \n",
      "0    0.696  \n",
      "1    0.720  \n",
      "2    0.423  \n",
      "3    0.667  \n",
      "4    0.440  \n"
     ]
    }
   ],
   "source": [
    "data = data[[\"tweet\", \"Positive\", \n",
    "             \"Negative\", \"Neutral\"]]\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3b4ea",
   "metadata": {},
   "source": [
    "Let us find out the most frequently assigned label as per the scores above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63fc1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sum(data[\"Positive\"])\n",
    "y = sum(data[\"Negative\"])\n",
    "z = sum(data[\"Neutral\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e62ff3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(a, b, c):\n",
    "    if (a>b) and (a>c):\n",
    "        print(\"Positive üòä \")\n",
    "    elif (b>a) and (b>c):\n",
    "        print(\"Negative üò† \")\n",
    "    else:\n",
    "        print(\"Neutral üôÇ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52385736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral üôÇ \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_score(x,y,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b077d",
   "metadata": {},
   "source": [
    "So, we see that most of the comments are neutral. Now, let us look at the individual scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "256853a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  2880.086000000009\n",
      "Negative:  7201.020999999922\n",
      "Neutral:  14696.887999999733\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \", x)\n",
    "print(\"Negative: \", y)\n",
    "print(\"Neutral: \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159fddf",
   "metadata": {},
   "source": [
    "##### We can see that the total of neutral tweets is way higher than positive or negative tweets. But, the number of negative tweets is also three-folds when compared to positive tweets. Thus,we can say that most of the opinions are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c1974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
